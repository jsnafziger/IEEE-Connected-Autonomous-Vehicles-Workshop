# IEEE-Connected-Autonomous-Vehicles-Workshop (2018)
http://ecewp.ece.wpi.edu/wordpress/conav/

## Visual Perception for Self-Driving Cars

We will motivate the problem and the challenges of vehicle environment perception by drawing intuition and reverse engineering existing self-driving car systems. A function system architecture will be discussed to help understand and decompose the complex system while highlighting relationships and to vehicle communications (V2X) technologies. Focus will be on real-time computer vision methods applied to the lane estimation use-case. We will explore, in detail, both classical computer vision methods and more recent deep learning approaches to lane estimation. The perception problem will be extended to scene understanding and behavior prediction by reviewing the dynamic object recognition problem and the components associated with the real-time tracking of environmental objects.

## Bibliography

### Reference Papers
* Ulbrich et. al., “Towards a Functional System Architecture for Automated Vehicles” (2017), https://arxiv.org/abs/1703.08557  
* Rieken et. al., “Toward Perception-Driven Urban Environment Modeling for Automated Road Vehicles” (2015), https://ieeexplore.ieee.org/document/7313216/ 
* Dickmanns and Mysliwetz, “Recursive 3-D Road and Relative Ego-State Recognition,” 1992.
* Bertozzi and Broggi, “GOLD: A parallel real-time stereo vision system for generic obstacle and lane detection,” 1998.
* Aly, “Real time detection of lane markers in urban streets,” 2008.
* Gurghian et. al., “DeepLanes : End-To-End Lane Position Estimation using Deep Neural Networks,” 2016.
* Huang, “Lane Estimation for Autonomous Vehicles using Vision and LIDAR”, (2010)
* J. Canny, A Computational Approach To Edge Detection, IEEE Trans. Pattern Analysis and Machine Intelligence, 8:679-714, 1986. 
* Xie and Tu, Holistically-Nested Edge Detection, ICCV 2015
* Arbel et.al., “Contour Detection and Hierarchical Image Segmentation”, TPAMI 2011
* Wang et.al., “LaneNet: Real-Time LaneNeven et.al., Detection Networks for Autonomous Driving”, 2018 https://arxiv.org/abs/1807.01726
* Neven et.al, “Towards End-to-End Lane Detection: an Instance Segmentation Approach”, 2018 https://arxiv.org/abs/1802.05591 
* Luo et. al. “Multiple Object Tracking: A Literature Review”, 2017
* Serre et al, “A feedforward architecture accounts for rapid categorization”, PNAS (2007)
* Huang et al, "Speed/accuracy trade-offs for modern convolutional object detectors", https://arxiv.org/abs/1611.10012 
* Wojke, “Simple online and realtime tracking with a deep association metric”, 2017


### Youtube Videos
* https://www.youtube.com/watch?v=I39sxwYKlEE 
* https://www.youtube.com/watch?v=tiwVMrTLUWg
* https://www.youtube.com/watch?v=LSX3qdy0dFg 
* https://www.youtube.com/watch?v=KXpZ6B1YB_k 
* https://www.youtube.com/watch?v=MPU2HistivI 


### Other Weblinks
* https://www.nvidia.com/en-us/self-driving-cars/hd-mapping/ 
* https://www.bosch-mobility-solutions.us/us/highlights/automated-mobility/radar-road-signature/index.html 
* http://wad.ai/challenge.html 
* https://github.com/Nikasa1889/HistoryObjectRecognition 
* http://www.mohamedaly.info/datasets/caltech-lanes 
* https://github.com/udacity/CarND-LaneLines-P1  
* https://pjreddie.com/darknet/yolo/ 
* https://www.mathworks.com/help/vision/examples/using-kalman-filter-for-object-tracking.html 
* http://www.cvlibs.net/datasets/kitti/ 
* https://motchallenge.net/ 

